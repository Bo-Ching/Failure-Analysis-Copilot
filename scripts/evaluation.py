import json
import torch
from bert_score import score as bert_score
from rouge_score import rouge_scorer
from datasets import load_metric

def load_data(predictions_file, references_file):
    """è¼‰å…¥ RAG ç”Ÿæˆçš„å›ç­”èˆ‡é»ƒé‡‘æ¨™æº–ç­”æ¡ˆ"""
    with open(predictions_file, "r", encoding="utf-8") as f:
        predictions = json.load(f)
    
    with open(references_file, "r", encoding="utf-8") as f:
        references = json.load(f)
    
    return predictions, references

def evaluate_bert_score(predictions, references, model_type="bert-base-uncased"):
    """è¨ˆç®— BERTScore"""
    P, R, F1 = bert_score(predictions, references, lang="en", model_type=model_type)
    return {
        "BERTScore_P": P.mean().item(),
        "BERTScore_R": R.mean().item(),
        "BERTScore_F1": F1.mean().item()
    }

def evaluate_rouge(predictions, references):
    """è¨ˆç®— ROUGE åˆ†æ•¸"""
    scorer = rouge_scorer.RougeScorer(["rouge1", "rouge2", "rougeL"], use_stemmer=True)
    rouge_results = {"ROUGE-1": [], "ROUGE-2": [], "ROUGE-L": []}

    for pred, ref in zip(predictions, references):
        scores = scorer.score(ref, pred)
        rouge_results["ROUGE-1"].append(scores["rouge1"].fmeasure)
        rouge_results["ROUGE-2"].append(scores["rouge2"].fmeasure)
        rouge_results["ROUGE-L"].append(scores["rougeL"].fmeasure)

    return {
        "ROUGE-1": sum(rouge_results["ROUGE-1"]) / len(rouge_results["ROUGE-1"]),
        "ROUGE-2": sum(rouge_results["ROUGE-2"]) / len(rouge_results["ROUGE-2"]),
        "ROUGE-L": sum(rouge_results["ROUGE-L"]) / len(rouge_results["ROUGE-L"]),
    }

def main(predictions_file="rag_predictions.json", references_file="ground_truth.json", output_file="evaluation_results.json"):
    """ä¸»å‡½å¼ï¼šè¼‰å…¥æ•¸æ“šä¸¦è¨ˆç®— BERTScore å’Œ ROUGE"""
    print("ğŸ“¥ è®€å– RAG ç”Ÿæˆçš„ç­”æ¡ˆèˆ‡é»ƒé‡‘æ¨™æº–ç­”æ¡ˆ...")
    predictions, references = load_data(predictions_file, references_file)

    print("è¨ˆç®— BERTScore...")
    bert_results = evaluate_bert_score(predictions, references)

    print("è¨ˆç®— ROUGE åˆ†æ•¸...")
    rouge_results = evaluate_rouge(predictions, references)

    results = {**bert_results, **rouge_results}

    # å„²å­˜çµæœ
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=4)
    
    print(f"è©•ä¼°çµæœå·²å„²å­˜è‡³ {output_file}")

if __name__ == "__main__":
    main()
